{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of HACKANONS COLAB 25GB RAM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c2f7c51626554bd197a35802ba734095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ea3911fd138545d6962e5908cedb59ef",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4af1d576313c47828a9c8c67c16712af",
              "IPY_MODEL_21dbb571ff2d4a318945ed8d29a5fe81"
            ]
          }
        },
        "ea3911fd138545d6962e5908cedb59ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4af1d576313c47828a9c8c67c16712af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3608d79a98af41ba974e3190ec550cdb",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5afeb9c88e774d54a819f607d51d0108"
          }
        },
        "21dbb571ff2d4a318945ed8d29a5fe81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7aaab27776154481a7b87ef4c46b87af",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 314kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_17bb4c73b46c4924ba12bd8a979c78b4"
          }
        },
        "3608d79a98af41ba974e3190ec550cdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5afeb9c88e774d54a819f607d51d0108": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7aaab27776154481a7b87ef4c46b87af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "17bb4c73b46c4924ba12bd8a979c78b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2279c3b548cd4568bd99d5d984e0db6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_153881f851e54f039ba5ab9ed7114b86",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_44a7781aaea948a1862296565bc9cad7",
              "IPY_MODEL_76cf401c475f454fb81f9cdf7515d2c9"
            ]
          }
        },
        "153881f851e54f039ba5ab9ed7114b86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44a7781aaea948a1862296565bc9cad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_45e511d940384d11a15aaa29f0d91fd5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_768fb2433356480b89b5f64fac1eafce"
          }
        },
        "76cf401c475f454fb81f9cdf7515d2c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f4bfb52a7de048dcaf5d75d4bb025e55",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 474B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1d3414f43ef4cf5a827b70764a7eb90"
          }
        },
        "45e511d940384d11a15aaa29f0d91fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "768fb2433356480b89b5f64fac1eafce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4bfb52a7de048dcaf5d75d4bb025e55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1d3414f43ef4cf5a827b70764a7eb90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "442ac2279cb94ee48b019c823f871641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a70e5b77ffe647fbb529eb04d8bc3fbb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_def16daf7d9e471aab490e5f0b1b06a8",
              "IPY_MODEL_1b1d0620de164c44b212a80f18da3f04"
            ]
          }
        },
        "a70e5b77ffe647fbb529eb04d8bc3fbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "def16daf7d9e471aab490e5f0b1b06a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7abe1ef87a6c4057a2fd5b8054109fc1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b888ab1a707741388ff2620a6b9588d1"
          }
        },
        "1b1d0620de164c44b212a80f18da3f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2c8e39ed583e467d875d3b0eeee4689c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:07&lt;00:00, 62.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee774cb212c94e25ab2fc01148caf9e4"
          }
        },
        "7abe1ef87a6c4057a2fd5b8054109fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b888ab1a707741388ff2620a6b9588d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c8e39ed583e467d875d3b0eeee4689c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee774cb212c94e25ab2fc01148caf9e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cbgwZWWfWpp"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAb77yZ9fzMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddeb5221-1d33-4aea-b9dc-c944a07d3fd8"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Feb 28 20:59:54 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pafL7Li0jyXW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpZ4QNY9PQq4"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wa6Hv8cPhqF",
        "outputId": "2825f362-21a3-45de-8ca5-c7e00400847f"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 40.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 69.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=41f1284bf3c982af4256aebab1c7ab12cff9112e063c6d08c53691561f69f919\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqcA94LoPjRJ",
        "outputId": "c8a90b15-013e-43ac-e3a4-87424d27ad88"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXnISsj2P2yU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "c2f7c51626554bd197a35802ba734095",
            "ea3911fd138545d6962e5908cedb59ef",
            "4af1d576313c47828a9c8c67c16712af",
            "21dbb571ff2d4a318945ed8d29a5fe81",
            "3608d79a98af41ba974e3190ec550cdb",
            "5afeb9c88e774d54a819f607d51d0108",
            "7aaab27776154481a7b87ef4c46b87af",
            "17bb4c73b46c4924ba12bd8a979c78b4",
            "2279c3b548cd4568bd99d5d984e0db6a",
            "153881f851e54f039ba5ab9ed7114b86",
            "44a7781aaea948a1862296565bc9cad7",
            "76cf401c475f454fb81f9cdf7515d2c9",
            "45e511d940384d11a15aaa29f0d91fd5",
            "768fb2433356480b89b5f64fac1eafce",
            "f4bfb52a7de048dcaf5d75d4bb025e55",
            "a1d3414f43ef4cf5a827b70764a7eb90",
            "442ac2279cb94ee48b019c823f871641",
            "a70e5b77ffe647fbb529eb04d8bc3fbb",
            "def16daf7d9e471aab490e5f0b1b06a8",
            "1b1d0620de164c44b212a80f18da3f04",
            "7abe1ef87a6c4057a2fd5b8054109fc1",
            "b888ab1a707741388ff2620a6b9588d1",
            "2c8e39ed583e467d875d3b0eeee4689c",
            "ee774cb212c94e25ab2fc01148caf9e4"
          ]
        },
        "outputId": "9758bfcc-4573-45dd-9f71-a4b98623415e"
      },
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "base_model = BertModel.from_pretrained(\"bert-base-uncased\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2f7c51626554bd197a35802ba734095",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2279c3b548cd4568bd99d5d984e0db6a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "442ac2279cb94ee48b019c823f871641",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECRbURekbBqn"
      },
      "source": [
        "path = '/content/drive/MyDrive/CMCL Shared Task/Cleaned_GECO_Dataset.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "532757caFBYl",
        "outputId": "51cdeee4-038d-4967-da53-c274c7e6134b"
      },
      "source": [
        "geco = pd.read_csv(path)\n",
        "geco.drop(columns = [\"Unnamed: 0\"], inplace = True)\n",
        "geco.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WORD_ID</th>\n",
              "      <th>WORD</th>\n",
              "      <th>WORD_GAZE_DURATION</th>\n",
              "      <th>WORD_GO_PAST_TIME</th>\n",
              "      <th>WORD_TOTAL_READING_TIME</th>\n",
              "      <th>sentence_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1-5-1</td>\n",
              "      <td>The</td>\n",
              "      <td>95</td>\n",
              "      <td>95</td>\n",
              "      <td>381</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1-5-2</td>\n",
              "      <td>intense</td>\n",
              "      <td>54</td>\n",
              "      <td>582</td>\n",
              "      <td>828</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1-5-3</td>\n",
              "      <td>interest</td>\n",
              "      <td>333</td>\n",
              "      <td>1097</td>\n",
              "      <td>565</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1-5-4</td>\n",
              "      <td>aroused</td>\n",
              "      <td>78</td>\n",
              "      <td>2107</td>\n",
              "      <td>428</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1-5-5</td>\n",
              "      <td>in</td>\n",
              "      <td>154</td>\n",
              "      <td>154</td>\n",
              "      <td>154</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  WORD_ID      WORD  ...  WORD_TOTAL_READING_TIME  sentence_id\n",
              "0   1-5-1       The  ...                      381            0\n",
              "1   1-5-2   intense  ...                      828            0\n",
              "2   1-5-3  interest  ...                      565            0\n",
              "3   1-5-4   aroused  ...                      428            0\n",
              "4   1-5-5        in  ...                      154            0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "pjSuWkDUFBa2",
        "outputId": "34bbf8bd-3abd-4868-ab1a-f72e3c1808a9"
      },
      "source": [
        "def scale(df):\n",
        "  df[\"WORD_GAZE_DURATION\"] /= 10\n",
        "  df[\"WORD_GO_PAST_TIME\"] /= 10\n",
        "  df[\"WORD_TOTAL_READING_TIME\"] /= 10\n",
        "  return\n",
        "scale(geco)\n",
        "geco.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WORD_ID</th>\n",
              "      <th>WORD</th>\n",
              "      <th>WORD_GAZE_DURATION</th>\n",
              "      <th>WORD_GO_PAST_TIME</th>\n",
              "      <th>WORD_TOTAL_READING_TIME</th>\n",
              "      <th>sentence_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1-5-1</td>\n",
              "      <td>The</td>\n",
              "      <td>9.5</td>\n",
              "      <td>9.5</td>\n",
              "      <td>38.1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1-5-2</td>\n",
              "      <td>intense</td>\n",
              "      <td>5.4</td>\n",
              "      <td>58.2</td>\n",
              "      <td>82.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1-5-3</td>\n",
              "      <td>interest</td>\n",
              "      <td>33.3</td>\n",
              "      <td>109.7</td>\n",
              "      <td>56.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1-5-4</td>\n",
              "      <td>aroused</td>\n",
              "      <td>7.8</td>\n",
              "      <td>210.7</td>\n",
              "      <td>42.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1-5-5</td>\n",
              "      <td>in</td>\n",
              "      <td>15.4</td>\n",
              "      <td>15.4</td>\n",
              "      <td>15.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  WORD_ID      WORD  ...  WORD_TOTAL_READING_TIME  sentence_id\n",
              "0   1-5-1       The  ...                     38.1            0\n",
              "1   1-5-2   intense  ...                     82.8            0\n",
              "2   1-5-3  interest  ...                     56.5            0\n",
              "3   1-5-4   aroused  ...                     42.8            0\n",
              "4   1-5-5        in  ...                     15.4            0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqN-22QJFBis",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "219ddd49-1233-4889-b3d5-25e8b9a85af3"
      },
      "source": [
        "def add_token_per_words(df):\n",
        "  n_tokens_per_word = []\n",
        "  cdf = 0\n",
        "  cf_n_token_per_word = []\n",
        "  for i, word in enumerate(df.WORD):\n",
        "    n_tokens_per_word.append(len(tokenizer.encode(word)) - 2)\n",
        "    if (i > 0) and (df.loc[i-1, \"sentence_id\"] != df.loc[i, \"sentence_id\"]):\n",
        "      cdf = 0\n",
        "    cdf += len(tokenizer.encode(word)) - 2\n",
        "    cf_n_token_per_word.append(cdf)\n",
        "  df[\"n_tokens\"] = n_tokens_per_word\n",
        "  df[\"cf_n_tokens\"] = cf_n_token_per_word\n",
        "  return df\n",
        "\n",
        "add_token_per_words(geco)\n",
        "geco.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WORD_ID</th>\n",
              "      <th>WORD</th>\n",
              "      <th>WORD_GAZE_DURATION</th>\n",
              "      <th>WORD_GO_PAST_TIME</th>\n",
              "      <th>WORD_TOTAL_READING_TIME</th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>n_tokens</th>\n",
              "      <th>cf_n_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1-5-1</td>\n",
              "      <td>The</td>\n",
              "      <td>9.5</td>\n",
              "      <td>9.5</td>\n",
              "      <td>38.1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1-5-2</td>\n",
              "      <td>intense</td>\n",
              "      <td>5.4</td>\n",
              "      <td>58.2</td>\n",
              "      <td>82.8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1-5-3</td>\n",
              "      <td>interest</td>\n",
              "      <td>33.3</td>\n",
              "      <td>109.7</td>\n",
              "      <td>56.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1-5-4</td>\n",
              "      <td>aroused</td>\n",
              "      <td>7.8</td>\n",
              "      <td>210.7</td>\n",
              "      <td>42.8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1-5-5</td>\n",
              "      <td>in</td>\n",
              "      <td>15.4</td>\n",
              "      <td>15.4</td>\n",
              "      <td>15.4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  WORD_ID      WORD  WORD_GAZE_DURATION  ...  sentence_id  n_tokens  cf_n_tokens\n",
              "0   1-5-1       The                 9.5  ...            0         1            1\n",
              "1   1-5-2   intense                 5.4  ...            0         1            2\n",
              "2   1-5-3  interest                33.3  ...            0         1            3\n",
              "3   1-5-4   aroused                 7.8  ...            0         1            4\n",
              "4   1-5-5        in                15.4  ...            0         1            5\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZOItGi_yyEM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "cb94bd62-8996-453c-a7f6-7e7744adcdc5"
      },
      "source": [
        "def form_sentences(df):\n",
        "  sentences = []\n",
        "  cdfs = []\n",
        "  targets = []\n",
        "  MAX_LEN = 0\n",
        "  for i in range(8066):\n",
        "    sentence = (' ').join(df[df.sentence_id == i].WORD)\n",
        "    target = [list(ele) for ele in df[df.sentence_id == i].iloc[:, 2:5].values]\n",
        "    cdf = list(np.array(df[df.sentence_id == i].loc[:, \"cf_n_tokens\"]))\n",
        "    sentences.append(sentence)\n",
        "    targets.append(target)\n",
        "    cdfs.append(cdf)\n",
        "    MAX_LEN = max(MAX_LEN, len(sentence.split()))\n",
        "  return sentences, targets, cdfs, MAX_LEN\n",
        "\n",
        "sentences, targets, cdfs, MAX_LEN = form_sentences(geco)\n",
        "sentences[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"The intense interest aroused in the public by what was known at the time as 'The Styles Case' has now somewhat subsided. Nevertheless, in view of the world-wide notoriety which attended it, I have been asked, both by my friend Poirot and the family themselves, to write an account of the whole story. This, we trust, will effectually silence the sensational rumours which still persist. I will therefore briefly set down the circumstances which led to my being connected with the affair.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XLeO5D8Kkep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc048c4-5458-4a4a-c6cc-197037be5e08"
      },
      "source": [
        "MAX_LEN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "143"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5brJH7hDFBfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfe806f3-1d7b-41d5-b91b-3f9a74b20a3b"
      },
      "source": [
        "np.array(targets[0]).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(82, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZGbFbj6yyG6"
      },
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class EyeGaze_dataset(Dataset):\n",
        "  def __init__(self, sentencess, targets, cdfs, tokenizer):\n",
        "    self.sentences = sentences               # List of Sentences\n",
        "    self.targets = targets                   # List of Padded Targets\n",
        "    self.tokenizer = tokenizer               # Tokenizer to be used (BERT)\n",
        "    self.cdfs = cdfs                         # Cumulative Frequency Function\n",
        "    #self.features = features\n",
        "    #self.tags = tags\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.sentences)               # No of Examples = 100\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sentence = str(self.sentences[index])        # Get the review at the particular index\n",
        "    target = self.targets[index]                    # Get the target label at the particular index\n",
        "    cdf = self.cdfs[index]\n",
        "    #feature = {}\n",
        "    #for key in features.keys():\n",
        "    #  feature[key] = features[key][index]\n",
        "    #tag = tags[index]\n",
        "    encoding = self.tokenizer.encode_plus(   # Encoder encoding the particular review\n",
        "        sentence,\n",
        "        return_attention_mask = True,\n",
        "        padding = \"max_length\",\n",
        "        max_length = 200,\n",
        "        return_tensors = \"pt\"\n",
        "    )\n",
        "    # The class simply returns a dictionary of the following\n",
        "    return_dict = {\"target\":torch.tensor(target, dtype = torch.float32),\n",
        "                   \"input_ids\":encoding[\"input_ids\"].flatten(),\n",
        "                   \"attention_mask\":encoding[\"attention_mask\"].flatten(),\n",
        "                   \"cdf\": torch.tensor(cdf, dtype = torch.int16)}\n",
        "                   \n",
        "                   #\"tag\":torch.tensor(tag, dtype = torch.float32)}\n",
        "    #for key in features.keys():\n",
        "    #  return_dict[key] = torch.tensor(feature[key], dtype = torch.float32)\n",
        "\n",
        "    return return_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwq1_8ziyyJf"
      },
      "source": [
        "def create_data_loader(sentences, targets, cdfs, tokenizer, batch_size):\n",
        "  data = EyeGaze_dataset(sentences, targets, cdfs, tokenizer)\n",
        "  train_data_loader = DataLoader(data, batch_size = batch_size, shuffle = False)\n",
        "  \n",
        "  return train_data_loader\n",
        "\n",
        "BATCH_SIZE = 1\n",
        "data_loader = create_data_loader(sentences, targets, cdfs, tokenizer, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7d2AgEs1GFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "357f49ad-50d3-4063-a547-a717800066b1"
      },
      "source": [
        "temp = next(iter(data_loader))\n",
        "print(temp.keys())\n",
        "keys = ['target', 'input_ids', 'attention_mask', 'cdf']\n",
        "for key in keys:\n",
        "  print(temp[key].size())\n",
        "m = 0\n",
        "for d in data_loader:\n",
        "  m = max(m, d[\"input_ids\"].size()[1])\n",
        "print(m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['target', 'input_ids', 'attention_mask', 'cdf'])\n",
            "torch.Size([1, 82, 3])\n",
            "torch.Size([1, 200])\n",
            "torch.Size([1, 200])\n",
            "torch.Size([1, 82])\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGhPr1X33E6G"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJp6-Enx5Cn-"
      },
      "source": [
        "class LanguageHeadLayer(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LanguageHeadLayer, self).__init__()\n",
        "    self.mid = torch.nn.Linear(in_features = base_model.config.hidden_size, out_features = 256)\n",
        "    self.out = torch.nn.Linear(in_features = 256, out_features = 256)\n",
        "    self.act1 = torch.nn.ReLU()\n",
        "    self.act2 = torch.nn.GELU()\n",
        "    self.drop = torch.nn.Dropout(p = 0.3)\n",
        "\n",
        "  def forward(self, output):\n",
        "    output = self.mid(output)\n",
        "    output = self.act2(output)\n",
        "    output = self.drop(output)\n",
        "\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jXOqbJ24VAh"
      },
      "source": [
        "class EyeGazeClassifier(torch.nn.Module):\n",
        "  def __init__(self, num_targets = 3):\n",
        "    super(EyeGazeClassifier, self).__init__()\n",
        "    self.base_model = base_model\n",
        "    self.languageheadlayer = LanguageHeadLayer()\n",
        "    self.out = torch.nn.Linear(in_features = 256, out_features = num_targets)\n",
        "\n",
        "  def map_predictions(self, outputs, attention_masks, cdfs):\n",
        "    for i in range(outputs.size()[0]):    \n",
        "      output = outputs[i]\n",
        "      attention_mask = attention_masks[i]\n",
        "      cdf = cdfs[i]\n",
        "\n",
        "      #attention_mask[0] = 0\n",
        "      #attention_mask[-1] = 0\n",
        "      attention_mask = torch.unsqueeze(attention_mask, dim = 1)\n",
        "\n",
        "      output = output*attention_mask\n",
        "\n",
        "      pred_tensor = torch.unsqueeze(torch.mean(output[1:cdf[0]+1], dim = 0), dim = 0)\n",
        "\n",
        "      for j in range(0, len(cdf)-1):\n",
        "        if (cdf[j+1] != 0):\n",
        "          y = torch.unsqueeze(torch.mean(output[cdf[j]+1:cdf[j+1]+1], dim = 0), dim = 0)\n",
        "          pred_tensor = torch.cat((pred_tensor, y), dim = 0)\n",
        "\n",
        "      #pred_pad = torch.tensor([[0 for a in range(768)] for k in range(MAX_LEN - pred_tensor.size()[0])], dtype = torch.float32).to(device)\n",
        "      #pred_tensor = torch.cat((pred_tensor, pred_pad), dim = 0)\n",
        "      if i==0:\n",
        "        pred_tensors = torch.unsqueeze(pred_tensor, dim = 0)\n",
        "      else:\n",
        "        pred_tensors = torch.cat((pred_tensors, torch.unsqueeze(pred_tensor, dim = 0)), dim = 0)\n",
        "\n",
        "    return pred_tensors\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, cdf):\n",
        "    lang_output = self.base_model(input_ids = input_ids, attention_mask = attention_mask)\n",
        "    lang_output = self.map_predictions(lang_output[\"last_hidden_state\"], attention_mask, cdf)\n",
        "    lang_output = self.languageheadlayer(lang_output)\n",
        "    #feature_output = self.feature_model(extra_features)\n",
        "    #output = (lang_output+feature_output)/2\n",
        "    \n",
        "    output = self.out(lang_output)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWjbqa9h4VCf"
      },
      "source": [
        "#del model\n",
        "model = EyeGazeClassifier(3)\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13twHnqj4VFT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG1nv6-J3dj1"
      },
      "source": [
        "#@title\n",
        "def target_initialise():\n",
        "  targets = {}\n",
        "  outputs = {}\n",
        "\n",
        "  targets[\"r20\"] = torch.tensor([], dtype = torch.float32)\n",
        "  targets[\"r21\"] = torch.tensor([], dtype = torch.float32)\n",
        "  targets[\"r22\"] = torch.tensor([], dtype = torch.float32)\n",
        "  \n",
        "  outputs[\"pred_r20\"] = torch.tensor([], dtype = torch.float32)\n",
        "  outputs[\"pred_r21\"] = torch.tensor([], dtype = torch.float32)\n",
        "  outputs[\"pred_r22\"] = torch.tensor([], dtype = torch.float32)\n",
        "  \n",
        "  return targets, outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSh4chlC3e44"
      },
      "source": [
        "#@title\n",
        "def store_targets(targets, target):\n",
        "  targets[\"r20\"] = torch.cat([targets[\"r20\"], target[0,:,0].detach().cpu()], dim = 0)\n",
        "  targets[\"r21\"] = torch.cat([targets[\"r21\"], target[0,:,1].detach().cpu()], dim = 0)\n",
        "  targets[\"r22\"] = torch.cat([targets[\"r22\"], target[0,:,2].detach().cpu()], dim = 0)\n",
        "  \n",
        "  return targets  \n",
        "\n",
        "def store_outputs(outputs, output):\n",
        "  outputs[\"pred_r20\"] = torch.cat([outputs[\"pred_r20\"], output[0,:,0].detach().cpu()], dim = 0)\n",
        "  outputs[\"pred_r21\"] = torch.cat([outputs[\"pred_r21\"], output[0,:,1].detach().cpu()], dim = 0)\n",
        "  outputs[\"pred_r22\"] = torch.cat([outputs[\"pred_r22\"], output[0,:,2].detach().cpu()], dim = 0)\n",
        "  \n",
        "  return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REwHABWg3e7E"
      },
      "source": [
        "EPOCHS = 1\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "opt_params = [{\"params\": model.languageheadlayer.parameters()},\n",
        "              {\"params\": model.out.parameters()}]\n",
        "\n",
        "partial_optimizer = AdamW(opt_params, lr=2e-7, betas = (0.9, 0.999), correct_bias=False)\n",
        "total_optimizer = AdamW(model.parameters(), lr = 6e-5, betas = (0.9, 0.999), correct_bias = False)\n",
        "\n",
        "total_steps = len(data_loader) * EPOCHS\n",
        "\n",
        "partial_scheduler = get_linear_schedule_with_warmup(\n",
        "  partial_optimizer,\n",
        "  num_warmup_steps=6,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "total_scheduler = get_linear_schedule_with_warmup(\n",
        "  total_optimizer,\n",
        "  num_warmup_steps=4,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.L1Loss(reduction = \"mean\").to(device)  # reduction = \"mean\" can be used"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZrnAs933e96"
      },
      "source": [
        "#@title\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=20, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22yi3XeVeTM_"
      },
      "source": [
        "def save(history, best):\n",
        "  for key, value in history.items():\n",
        "    best[key] = value[-1]\n",
        "\n",
        "  return best\n",
        "\n",
        "def update(history, train_loss, train_r2):\n",
        "  \n",
        "  history['train_loss'].append(train_loss)\n",
        "\n",
        "  history[\"train_nFix\"].append(train_r2[\"nFix\"])\n",
        "  history[\"train_GPT\"].append(train_r2[\"GPT\"])\n",
        "  history[\"train_TRT\"].append(train_r2[\"TRT\"])\n",
        "\n",
        "\n",
        "  return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocz2RE7n1GHm"
      },
      "source": [
        "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  targets, outputs = target_initialise()  \n",
        "  r2 = {}\n",
        "  with torch.autograd.set_detect_anomaly(True):\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      target = d[\"target\"].to(device)\n",
        "      cdf = d[\"cdf\"].to(device)\n",
        "      #char_len = torch.unsqueeze(d[\"n_chars\"], dim = 2)\n",
        "      #char_len_lemmatized = torch.unsqueeze(d[\"n_char_lemmatized\"], dim = 2)\n",
        "      #if_stopword = torch.unsqueeze(d[\"stopword\"], dim = 2)\n",
        "      #if_num = torch.unsqueeze(d['number'], dim = 2)\n",
        "      #if_end = torch.unsqueeze(d[\"endword\"], dim = 2)\n",
        "      #tfidf = torch.unsqueeze(d[\"tf_idf\"], dim = 2)\n",
        "      #tag = d[\"tag\"]\n",
        "\n",
        "      targets = store_targets(targets, target)\n",
        "      #extra_feature = torch.cat((char_len, char_len_lemmatized, if_stopword, if_num, if_end, tfidf, tag), dim = 2).to(device)\n",
        "\n",
        "      output = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        cdf = cdf,\n",
        "        )\n",
        "\n",
        "      outputs = store_outputs(outputs, output)\n",
        "      \n",
        "      loss = loss_fn(output, target)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "      loss.backward()\n",
        "      nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "      optimizer.zero_grad()\n",
        "    \n",
        "    r2[\"nFix\"] = r2_score(targets[\"r20\"].numpy(), outputs[\"pred_r20\"].numpy())\n",
        "    r2[\"GPT\"] = r2_score(targets[\"r21\"].numpy(), outputs[\"pred_r21\"].numpy())\n",
        "    r2[\"TRT\"] = r2_score(targets[\"r22\"].numpy(), outputs[\"pred_r22\"].numpy())\n",
        "    \n",
        "  return np.mean(losses), r2    # correct_predictions.double() / n_examples,"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wpRXCPa1GJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85aaba0f-9eda-4685-ba6f-e22c342dd747"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "history = defaultdict(list)\n",
        "tolerance = 0\n",
        "best = {}\n",
        "best = {\"train_loss\" : 10000}\n",
        "early_stopping = EarlyStopping(patience = 5, verbose = True, delta = 0.001)\n",
        "\n",
        "optimizer = total_optimizer\n",
        "scheduler = total_scheduler\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 120)\n",
        "\n",
        "\n",
        "  train_loss, train_r2 = train_epoch(model,\n",
        "    data_loader,    \n",
        "    loss_fn, \n",
        "    optimizer, \n",
        "    device, \n",
        "    scheduler)\n",
        "  \n",
        "\n",
        "  print(f'Train loss {train_loss} and Train R2 {train_r2}')\n",
        "\n",
        "\n",
        "  history = update(history, train_loss, train_r2)\n",
        "  \n",
        "  if train_loss < best[\"train_loss\"]:\n",
        "    best = save(history, best)\n",
        "  \n",
        "  early_stopping(train_loss, model)\n",
        "  if early_stopping.early_stop:\n",
        "    print(\"Stopped Early at at Epoch \", epoch+1)\n",
        "    break\n",
        "  model.load_state_dict(torch.load('checkpoint.pt'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Train loss 14.329914672304376 and Train R2 {'nFix': 0.017769096554440034, 'GPT': -0.012850411684996121, 'TRT': 0.006025899502727916}\n",
            "Validation loss decreased (inf --> 14.329915).  Saving model ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIhI0mdZ1GN-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "2e3a9865-a84d-41cf-dd23-1636d0c99a91"
      },
      "source": [
        "plt.plot(history[\"train_loss\"], c = \"r\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Train Loss\")\n",
        "plt.title(\"Loss vs Epochs\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcZHq1JpmGC7"
      },
      "source": [
        "save_file_path = \"/content/drive/My Drive/CMCL Shared Task/GecoBERT-agp.pth\"\n",
        "torch.save(model.state_dict(), save_file_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKF_gxe0lMpL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "004d5287-1b14-4904-be28-79780f3772c3"
      },
      "source": [
        "len(data_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8066"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0zWW5GyPnij"
      },
      "source": [
        "'''\n",
        "#training_data_file_path = \"/content/drive/My Drive/CMCL Shared Task/training_data.csv\"\n",
        "freq_table_file_path = \"/content/drive/MyDrive/CMCL Shared Task/unigram_freq.csv\"\n",
        "training_data_file_path = \"/content/drive/MyDrive/CMCL Shared Task/training_data.csv\"\n",
        "freq_table = pd.read_csv(freq_table_file_path)\n",
        "train_data = pd.read_csv(training_data_file_path)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH353jjBppgY"
      },
      "source": [
        "'''\n",
        "def remove_eos(df):\n",
        "  cnt = 1\n",
        "  endword = []\n",
        "  for i in range(df.shape[0]-1):\n",
        "    if (df.loc[i+1, \"sentence_id\"] == cnt):\n",
        "      df.loc[i, \"word\"] = df.loc[i, \"word\"][:-6]   # Remove <EOS> for the last word of each sentence.\n",
        "      cnt += 1\n",
        "      endword.append(1)\n",
        "    else:\n",
        "      endword.append(-1) \n",
        "  s = df.loc[df.shape[0] - 1, \"word\"]              # Remove <EOS> for last element separately\n",
        "  df.loc[df.shape[0] - 1, \"word\"] = s[:-6]\n",
        "  endword.append(-1)\n",
        "  df[\"endword\"] = endword \n",
        "  return df\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_EHU-JoGlfj"
      },
      "source": [
        "'''\n",
        "def make_freq_col(df, freq_table):\n",
        "  freq = []\n",
        "  for word in df.word:\n",
        "    if freq_table[\"count\"][freq_table.word == word].size == 0:\n",
        "      freq.append(0)\n",
        "    else:\n",
        "      freq.append(freq_table[\"count\"][freq_table.word == word].item())\n",
        "  df[\"freq\"] = freq\n",
        "\n",
        "  return df\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mQ9tJwCOVYU"
      },
      "source": [
        "'''\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "def normalise_freq(df):\n",
        "  df[\"freq\"] = scaler.fit_transform(df[\"freq\"].to_numpy().reshape(-1, 1))\n",
        "  return df\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1SoGFU6NTbo"
      },
      "source": [
        "# CHECK DEBUGGING BEGIN\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H1UO0I_BfKs"
      },
      "source": [
        "'''\n",
        "# output-> BERT outputs\n",
        "# repeated values imply words breaking into tokens during tokenizer\n",
        "\n",
        "output = torch.tensor([0.05, 1.0, 2, 2, 3, 4, 5, 6, 6, 6, 7, 9.5])\n",
        "\n",
        "# 0.19 -> CLS token embedding\n",
        "# 9.99 -> SEP token embedding\n",
        "\n",
        "cdf = [1, 3, 4, 5, 6, 9, 10]\n",
        "attention_mask  = torch.tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0])\n",
        "map_predictions1(output, attention_mask, cdf)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHsLYZ1OBTt7"
      },
      "source": [
        "'''\n",
        "# COPIED FROM STANDARDISED ROBERTA FEATURES...\n",
        "def map_predictions1(output, attention_mask, cdf):\n",
        "  attention_mask[0][0] = 0\n",
        "  attention_mask[0][-1] = 0\n",
        "  attention_mask = torch.unsqueeze(attention_mask, dim = 2)\n",
        "  output = torch.mul(output, attention_mask)[0]\n",
        "  print(\"Output dims after mul = \", output.size())\n",
        "  pred_tensor = torch.unsqueeze(torch.mean(output[1:cdf[0]+1], dim = 0), dim = 0)\n",
        "  print(\"Pred tensor dims = \", pred_tensor.size())\n",
        "  for i in range(0, len(cdf)-1):\n",
        "    y = torch.unsqueeze(torch.mean(output[cdf[i]+1:cdf[i+1]+1], dim = 0), dim = 0)\n",
        "    pred_tensor = torch.cat((pred_tensor, y), dim = 0)\n",
        "  return pred_tensor\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riIVfcj0BfM3"
      },
      "source": [
        "'''\n",
        "words = [\"Happy\", \"Birthday\", \"to\", \"Carlucci!\"]    # Similar to words in df\n",
        "sample_sent = (' ').join(words)                     # Forming sentences\n",
        "encoding = tokenizer.encode_plus(sample_sent, add_special_tokens = True, return_attention_mask = True, return_tensors = \"pt\")   # Tokenize\n",
        "encoding         \n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMFzr1vXIN8T"
      },
      "source": [
        "'''\n",
        "# CALCULATE CF_TOKENS AS IN FUNCTION FROM NOTEBOOK STANDARDIZED ROBERTA ....\n",
        "n_tokens_per_word = []\n",
        "cdf = 0\n",
        "cf_n = []\n",
        "for i, word in enumerate(words):\n",
        "  n_tokens_per_word.append(len(tokenizer.encode(word)) - 2)\n",
        "  cdf += len(tokenizer.encode(word)) - 2\n",
        "  cf_n.append(cdf)\n",
        "cf_n\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sidMSPlZBfPy"
      },
      "source": [
        "'''\n",
        "# Output -> BERT output\n",
        "# pred -> output after map predictions\n",
        "\n",
        "output = base_model(input_ids = encoding[\"input_ids\"], attention_mask = encoding[\"attention_mask\"])[\"last_hidden_state\"]\n",
        "preds = map_predictions1(output, encoding[\"attention_mask\"], cf_n)\n",
        "output = torch.squeeze(output)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3X7jf4oNZLL"
      },
      "source": [
        "# CHECK DEBUGGING END"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt1E_eNNGVNB"
      },
      "source": [
        "'''\n",
        "#Using Pearson Correlation\n",
        "plt.figure(figsize=(18,16))\n",
        "corr = df.iloc[:, 2:].corr()\n",
        "sns.heatmap(corr, annot=True, cmap=plt.cm.Reds)\n",
        "plt.show()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKb56STgUfUk"
      },
      "source": [
        "'''\n",
        "from sklearn.feature_selection import f_classif\n",
        "\n",
        "keys = [\"nFix\", \"FFD\", \"GPT\", \"TRT\", \"fixProp\"]\n",
        "#for key in keys:\n",
        "score = f_classif(df.loc[:, keys], df[\"tags\"])\n",
        "data = pd.DataFrame(data = score, columns = keys, index = [\"F score\", \"p value\"])\n",
        "data\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHJ51ue6R4vw"
      },
      "source": [
        "#score = f_classif(df.loc[:, keys], df[\"number\"])\n",
        "#data = pd.DataFrame(data = score, columns = keys, index = [\"F score\", \"p value\"])\n",
        "#data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktp7kcFmVvZb"
      },
      "source": [
        "#score = f_classif(df.loc[:, keys], df[\"stopword\"])\n",
        "#data = pd.DataFrame(data = score, columns = keys, index = [\"F score\", \"p value\"])\n",
        "#data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrSlJPc6o9EI"
      },
      "source": [
        "'''\n",
        "from sklearn.feature_selection import f_classif\n",
        "\n",
        "df = remove_eos(train_data)\n",
        "keys = [\"nFix\", \"FFD\", \"GPT\", \"TRT\", \"fixProp\"]\n",
        "score = f_classif(df.loc[:, keys], df[\"endword\"])\n",
        "data = pd.DataFrame(data = score, columns = keys, index = [\"F score\", \"p value\"])\n",
        "data\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19hnfNHtW9Cj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6sF8hzDW8_z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3dVcbezW881"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cRTPzo_W86V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1K30qyuW83b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-YE-A6rW8zs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrKMj40JW8xF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RFmk4_RW8ub"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSgSBTL3lui7"
      },
      "source": [
        "#CrisisNLP Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hYzIuHeW8rz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iGI9Nx3W8pX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O5tuu8olqCx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6opZRxdSW9jE"
      },
      "source": [
        "#CrisisNLP Dataset Handling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTuPJrKGXF0W",
        "outputId": "e8187e88-059a-4dd9-f5ea-f172eca293dc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "342Vsak0XHhK"
      },
      "source": [
        "path= \"/content/drive/MyDrive/ChiSquareX_NLP_Tutoring/Multi_Lingual/CrisisNLP_labeled_data/CrisisNLP_labeled_data_crowdflower/\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCwq0-EiXUf_",
        "outputId": "28b81ad7-9263-4d41-c626-fdb193d67a80"
      },
      "source": [
        "cd /content/drive/MyDrive/ChiSquareX_NLP_Tutoring/Multi_Lingual/CrisisNLP_labeled_data/CrisisNLP_labeled_data_crowdflower/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ChiSquareX_NLP_Tutoring/Multi_Lingual/CrisisNLP_labeled_data/CrisisNLP_labeled_data_crowdflower\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "brPwnUi1XVVK",
        "outputId": "d9367c1b-87cd-491c-ff03-c713d0b1b30b"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/ChiSquareX_NLP_Tutoring/Multi_Lingual/CrisisNLP_labeled_data/CrisisNLP_labeled_data_crowdflower'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFtCSVsjXWhD",
        "outputId": "6bebc8e7-810d-43ce-d1b8-94eba65f01d4"
      },
      "source": [
        "ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \u001b[0m\u001b[01;34m2013_Pakistan_eq\u001b[0m/                 \u001b[01;34m2014_Middle_East_Respiratory_Syndrome_en\u001b[0m/\n",
            " \u001b[01;34m2014_California_Earthquake\u001b[0m/       \u001b[01;34m2014_Pakistan_floods\u001b[0m/\n",
            " \u001b[01;34m2014_Chile_Earthquake_cl\u001b[0m/         \u001b[01;34m2014_Philippines_Typhoon_Hagupit_en\u001b[0m/\n",
            " \u001b[01;34m2014_Chile_Earthquake_en\u001b[0m/         \u001b[01;34m2015_Cyclone_Pam_en\u001b[0m/\n",
            " \u001b[01;34m2014_ebola_cf\u001b[0m/                    \u001b[01;34m2015_Nepal_Earthquake_en\u001b[0m/\n",
            " \u001b[01;34m2014_Hurricane_Odile_Mexico_en\u001b[0m/   README.txt\n",
            " \u001b[01;34m2014_India_floods\u001b[0m/               'Terms of use.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxuiUNSqXXXB",
        "outputId": "bb416a25-e3a8-48ba-e150-21d70821fe13"
      },
      "source": [
        "cd 2014_Hurricane_Odile_Mexico_en/"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/ChiSquareX_NLP_Tutoring/Multi_Lingual/CrisisNLP_labeled_data/CrisisNLP_labeled_data_crowdflower/2014_Hurricane_Odile_Mexico_en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3Y2LYqrX9ds",
        "outputId": "15f8cbbf-4358-4c09-c65f-c812758cf853"
      },
      "source": [
        "ls"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2014_Hurricane_Odile_Mexico_en_CF_labeled_data.tsv  labeling-instructions.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8lc0JCZ1YDvs",
        "outputId": "ac16e1fe-7573-412d-d89d-dad30b907845"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/ChiSquareX_NLP_Tutoring/Multi_Lingual/CrisisNLP_labeled_data/CrisisNLP_labeled_data_crowdflower/2014_Hurricane_Odile_Mexico_en'"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zCo37BAYuVG"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4orJOq3GYop9"
      },
      "source": [
        "data= pd.DataFrame()\n",
        "data = pd.read_csv('2014_Hurricane_Odile_Mexico_en_CF_labeled_data.tsv', error_bad_lines=False, sep='\\t') "
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXtdhsNVY0v-",
        "outputId": "db377108-08af-4a7d-f0ea-a42d244e46c7"
      },
      "source": [
        "data.shape\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1262, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfpzK2I1ZTMt"
      },
      "source": [
        "data = data.drop(\"tweet_id\", axis=1)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5R7RHE8aBAO",
        "outputId": "27ef2f72-b403-4877-a486-066aa1e2d69a"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1262 entries, 0 to 1261\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   tweet_text  1262 non-null   object\n",
            " 1   label       1262 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 19.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oRt-0YYfErl",
        "outputId": "04948967-c689-44c8-9dc7-542b8d10b14e"
      },
      "source": [
        "len(data[data['label'] == \"not_related_or_irrelevant\"])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tM4ZO-gaLY3"
      },
      "source": [
        "data.loc[data.label == \"not_related_or_irrelevant\", 'not_related_or_irrelevant'] = 0\n",
        "data.loc[data.label != 'not_related_or_irrelevant', 'label'] = 1"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "yxjUmtX3bzZ9",
        "outputId": "7768a13a-cb84-473f-d2d2-a66dbe2188e1"
      },
      "source": [
        "data"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Prayers for Cabo: Hurricane Odile Roars Throug...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sammy Hagar's Home Damaged in Hurricane: Sammy...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Residents, Tourists Sent to Shelters as Hurric...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Our thoughts go out to all of our friends in L...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Does anyone have information on emergency serv...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1257</th>\n",
              "      <td>\"In the wake of Hurricane Odile’s destruction ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1258</th>\n",
              "      <td>LET'S HELP REBUILD BCS DEVASTATED BY HURRICANE...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1259</th>\n",
              "      <td>BBC News - Hurricane Odile damages Mexico's Ba...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1260</th>\n",
              "      <td>Coachella, keep it safe, remnants arriving soo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1261</th>\n",
              "      <td>RT @TLW3: Hurricane Odile Damages Update: Mexi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1262 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             tweet_text label\n",
              "0     Prayers for Cabo: Hurricane Odile Roars Throug...     1\n",
              "1     Sammy Hagar's Home Damaged in Hurricane: Sammy...     1\n",
              "2     Residents, Tourists Sent to Shelters as Hurric...     1\n",
              "3     Our thoughts go out to all of our friends in L...     1\n",
              "4     Does anyone have information on emergency serv...     1\n",
              "...                                                 ...   ...\n",
              "1257  \"In the wake of Hurricane Odile’s destruction ...     1\n",
              "1258  LET'S HELP REBUILD BCS DEVASTATED BY HURRICANE...     1\n",
              "1259  BBC News - Hurricane Odile damages Mexico's Ba...     1\n",
              "1260  Coachella, keep it safe, remnants arriving soo...     1\n",
              "1261  RT @TLW3: Hurricane Odile Damages Update: Mexi...     1\n",
              "\n",
              "[1262 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nd3AtDnwb-Lk",
        "outputId": "129ef7f1-a7f3-4e9e-b75b-ce293e972462"
      },
      "source": [
        "len(data[data['label'] == 0])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9EUsL9ZcayK",
        "outputId": "f64f780c-75cd-46b9-fb0d-7f4243679653"
      },
      "source": [
        "len(data[data['label'] == 1])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1262"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcrUx--_ckUE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}